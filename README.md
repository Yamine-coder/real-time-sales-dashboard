# üìà Real-Time Sales Dashboard

Ce projet met en ≈ìuvre une pipeline compl√®te de traitement et de visualisation de donn√©es de ventes en temps r√©el. Il s'appuie sur **Apache Kafka** pour l'ingestion, **Apache Spark Structured Streaming** pour le traitement, **PostgreSQL** pour le stockage, et **Dash (Python)** pour la visualisation via un tableau de bord dynamique.

## üéØ Objectif

- Simuler un flux de ventes en temps r√©el  
- Traiter les donn√©es en continu via Spark Streaming  
- Stocker les r√©sultats dans une base PostgreSQL  
- Afficher les KPIs de vente et l‚Äô√©tat des stocks en direct

## ‚öôÔ∏è Stack technique

| Technologie     | Usage                                                                 |
|----------------|------------------------------------------------------------------------|
| Kafka           | Ingestion des flux de vente en temps r√©el                             |
| Spark Streaming | Traitement des messages Kafka via Structured Streaming                |
| PostgreSQL      | Stockage des donn√©es de vente et des stocks                           |
| Dash (Python)   | Application de visualisation du tableau de bord                       |
| Docker Compose  | Orchestration des services dans des conteneurs                        |

## üöÄ Lancement du projet

```bash
# Cloner le projet
git clone https://github.com/Yamine-coder/real-time-sales-dashboard.git
cd real-time-sales-dashboard

# Lancer l‚Äôensemble de l‚Äôenvironnement
docker-compose up --build
```

- üìä Dashboard disponible sur : [http://localhost:8050](http://localhost:8050)  
- üóÑÔ∏è PostgreSQL disponible sur le port : `5432`

## üìÇ Structure du projet

```
‚îú‚îÄ‚îÄ producer/              ‚Üí Producteur Kafka en Python
‚îú‚îÄ‚îÄ spark_app/             ‚Üí Traitement Spark Streaming
‚îú‚îÄ‚îÄ app/                   ‚Üí Interface Dash pour visualisation
‚îú‚îÄ‚îÄ docker-compose.yml     ‚Üí Orchestration des services
‚îú‚îÄ‚îÄ README.md
```

## üß™ Donn√©es simul√©es

Chaque transaction contient :
- Timestamp (`datetime`)  
- ID produit  
- Quantit√© vendue  
- Stock restant apr√®s vente  

Les messages sont produits automatiquement et envoy√©s dans un topic Kafka, trait√©s en temps r√©el par Spark, puis stock√©s dans PostgreSQL.

## üé• D√©monstration vid√©o

[![Aper√ßu de la vid√©o](images/Capture real-time-dashboard.png) alt="Aper√ßu de la vid√©o" width="700"/>

> üìΩÔ∏è [Clique ici pour visionner la vid√©o compl√®te](./images/demo-real-time-dashboard.mp4)

## üë®‚Äçüíª Auteur

**Yamine Moussaoui**  
üéì MSc Intelligence Artificielle & Big Data  
üíº Consultant en Solutions Data & IA  
üîó [LinkedIn](https://www.linkedin.com/in/yamine-moussaoui-672a25205/)   
üìß moussaouiyamine1@gmail.com  
üîé [GitHub](https://github.com/Yamine-coder)



## üè∑Ô∏è Tags GitHub 

`real-time` `data-pipeline` `spark` `kafka` `postgresql` `dashboard` `data-engineering`

> *Une solution moderne et √©volutive pour visualiser l‚Äôactivit√© commerciale en temps r√©el.*
