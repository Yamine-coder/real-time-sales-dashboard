# ğŸ“ˆ Real-Time Sales Dashboard

Ce projet met en Å“uvre une pipeline complÃ¨te de traitement et de visualisation de donnÃ©es de ventes en temps rÃ©el. Il s'appuie sur **Apache Kafka** pour l'ingestion, **Apache Spark Structured Streaming** pour le traitement, **PostgreSQL** pour le stockage, et **Dash (Python)** pour la visualisation via un tableau de bord dynamique.

## ğŸ¯ Objectif

- Simuler un flux de ventes en temps rÃ©el  
- Traiter les donnÃ©es en continu via Spark Streaming  
- Stocker les rÃ©sultats dans une base PostgreSQL  
- Afficher les KPIs de vente et lâ€™Ã©tat des stocks en direct

## âš™ï¸ Stack technique

| Technologie     | Usage                                                                 |
|----------------|------------------------------------------------------------------------|
| Kafka           | Ingestion des flux de vente en temps rÃ©el                             |
| Spark Streaming | Traitement des messages Kafka via Structured Streaming                |
| PostgreSQL      | Stockage des donnÃ©es de vente et des stocks                           |
| Dash (Python)   | Application de visualisation du tableau de bord                       |
| Docker Compose  | Orchestration des services dans des conteneurs                        |

## ğŸš€ Lancement du projet

```bash
# Cloner le projet
git clone https://github.com/Yamine-coder/real-time-sales-dashboard.git
cd real-time-sales-dashboard

# Lancer lâ€™ensemble de lâ€™environnement
docker-compose up --build
```

- ğŸ“Š Dashboard disponible sur : [http://localhost:8050](http://localhost:8050)  
- ğŸ—„ï¸ PostgreSQL disponible sur le port : `5432`

## ğŸ“‚ Structure du projet

```
â”œâ”€â”€ producer/              â†’ Producteur Kafka en Python
â”œâ”€â”€ spark_app/             â†’ Traitement Spark Streaming
â”œâ”€â”€ app/                   â†’ Interface Dash pour visualisation
â”œâ”€â”€ docker-compose.yml     â†’ Orchestration des services
â”œâ”€â”€ README.md
```

## ğŸ§ª DonnÃ©es simulÃ©es

Chaque transaction contient :
- Timestamp (`datetime`)  
- ID produit  
- QuantitÃ© vendue  
- Stock restant aprÃ¨s vente  

Les messages sont produits automatiquement et envoyÃ©s dans un topic Kafka, traitÃ©s en temps rÃ©el par Spark, puis stockÃ©s dans PostgreSQL.

## ğŸ¥ DÃ©monstration vidÃ©o

<img src="./images/Capture real-time-dashboard" alt="AperÃ§u de la vidÃ©o" width="700"/>

> ğŸ“½ï¸ [Clique ici pour visionner la vidÃ©o complÃ¨te](./images/demo-real-time-dashboard.mp4)

## ğŸ‘¨â€ğŸ’» Auteur

**Yamine Moussaoui**  
ğŸ“ MSc Intelligence Artificielle & Big Data  
ğŸ’¼ Consultant en Solutions Data & IA  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/yamine-moussaoui-672a25205/)   
ğŸ“§ moussaouiyamine1@gmail.com  
ğŸ” [GitHub](https://github.com/Yamine-coder)



## ğŸ·ï¸ Tags GitHub 

`real-time` `data-pipeline` `spark` `kafka` `postgresql` `dashboard` `data-engineering`

> *Une solution moderne et Ã©volutive pour visualiser lâ€™activitÃ© commerciale en temps rÃ©el.*
